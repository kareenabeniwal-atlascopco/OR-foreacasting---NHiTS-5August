{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0e104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "from neuralforecast.losses.pytorch import DistributionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecade42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"GMRegions_CPI.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ec5aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'GM Region': 'unique_id',\n",
    "    'Month-Year': 'ds',\n",
    "    'CPI': 'trend',\n",
    "    'EUR': 'y'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb191a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berema</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1.130630e+06</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berema</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2.034458e+06</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berema</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>6.543391e+06</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berema</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>5.069735e+06</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berema</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>1.050716e+06</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds             y  trend\n",
       "0    Berema 2020-01-01  1.130630e+06   1.73\n",
       "1    Berema 2020-02-01  2.034458e+06   0.72\n",
       "2    Berema 2020-03-01  6.543391e+06   0.54\n",
       "3    Berema 2020-04-01  5.069735e+06   0.63\n",
       "4    Berema 2020-05-01  1.050716e+06   1.08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83792c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique series IDs\n",
    "unique_ids = df['unique_id'].unique()\n",
    "\n",
    "# One-hot encode without prefix\n",
    "static_features = pd.get_dummies(pd.DataFrame({'unique_id': unique_ids}),\n",
    "                                 columns=['unique_id'], prefix='', prefix_sep='').astype(int)\n",
    "\n",
    "# Add unique_id as the first column\n",
    "df_static = pd.DataFrame({'unique_id': unique_ids})\n",
    "df_static = pd.concat([df_static, static_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5e4aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>Berema</th>\n",
       "      <th>DACH and Benelux</th>\n",
       "      <th>Eastern Europe</th>\n",
       "      <th>France</th>\n",
       "      <th>Greater China</th>\n",
       "      <th>India</th>\n",
       "      <th>Liuzhou</th>\n",
       "      <th>MEN</th>\n",
       "      <th>Mexico and Central America</th>\n",
       "      <th>Scandinavia</th>\n",
       "      <th>South America</th>\n",
       "      <th>South Europe</th>\n",
       "      <th>UK and Ireland</th>\n",
       "      <th>US and Canada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berema</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DACH and Benelux</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eastern Europe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greater China</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unique_id  Berema  DACH and Benelux  Eastern Europe  France  \\\n",
       "0            Berema       1                 0               0       0   \n",
       "1  DACH and Benelux       0                 1               0       0   \n",
       "2    Eastern Europe       0                 0               1       0   \n",
       "3            France       0                 0               0       1   \n",
       "4     Greater China       0                 0               0       0   \n",
       "\n",
       "   Greater China  India  Liuzhou  MEN  Mexico and Central America  \\\n",
       "0              0      0        0    0                           0   \n",
       "1              0      0        0    0                           0   \n",
       "2              0      0        0    0                           0   \n",
       "3              0      0        0    0                           0   \n",
       "4              1      0        0    0                           0   \n",
       "\n",
       "   Scandinavia  South America  South Europe  UK and Ireland  US and Canada  \n",
       "0            0              0             0               0              0  \n",
       "1            0              0             0               0              0  \n",
       "2            0              0             0               0              0  \n",
       "3            0              0             0               0              0  \n",
       "4            0              0             0               0              0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a643ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: 2020-01-01 00:00:00 to 2024-12-01 00:00:00\n",
      "Test period: 2025-01-01 00:00:00 to 2025-03-01 00:00:00\n",
      "Number of series (regions): 14\n",
      "Train size: 840 rows  |  Test size: 42 rows\n"
     ]
    }
   ],
   "source": [
    "# Split data into training (up to 2024-12) and test (2025-01 to 2025-03)\n",
    "train_cutoff = pd.Timestamp('2025-01-01')\n",
    "df_train = df[df['ds'] < train_cutoff].copy()   # data up to Dec 2024\n",
    "df_test  = df[df['ds'] >= train_cutoff].copy()  # data from Jan 2025 onward\n",
    "\n",
    "print(\"Training period:\", df_train['ds'].min(), \"to\", df_train['ds'].max())\n",
    "print(\"Test period:\", df_test['ds'].min(), \"to\", df_test['ds'].max())\n",
    "print(\"Number of series (regions):\", df['unique_id'].nunique())\n",
    "print(\"Train size:\", len(df_train), \"rows  |  Test size:\", len(df_test), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b4e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "model = NHITS(h=12,\n",
    "              input_size=24,\n",
    "              loss=DistributionLoss(distribution='StudentT', level=[80, 90], return_params=True),\n",
    "              stat_exog_list=['Berema'],\n",
    "              futr_exog_list=['trend'],\n",
    "              n_freq_downsample=[2, 1, 1],\n",
    "              scaler_type='robust',\n",
    "              max_steps=200,\n",
    "              early_stop_patience_steps=2,\n",
    "              inference_windows_batch_size=1,\n",
    "              val_check_steps=10,\n",
    "              learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d85f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = NeuralForecast(models=[model], freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ad62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Prepare futr_df for prediction\n",
    "futr_df = df_test[['unique_id', 'ds', 'trend']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049366bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst.fit(df=df_train, static_df=df_static, val_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e45daa88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There are missing combinations of ids and times in `futr_df`.\nYou can run the `make_future_dataframe()` method to get the expected combinations or the `get_missing_future(futr_df)` method to get the missing combinations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mfcst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutr_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\neuralforecast\\core.py:933\u001b[0m, in \u001b[0;36mNeuralForecast.predict\u001b[1;34m(self, df, static_df, futr_df, verbose, engine, level, quantiles, **data_kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m         expected_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_future_dataframe(df)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    932\u001b[0m         missing_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_missing_future(futr_df, df)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are missing combinations of ids and times in `futr_df`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can run the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_cmd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` method to get the expected combinations or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cmd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` method to get the missing combinations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m futr_orig_rows \u001b[38;5;241m>\u001b[39m futr_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    939\u001b[0m     dropped_rows \u001b[38;5;241m=\u001b[39m futr_orig_rows \u001b[38;5;241m-\u001b[39m futr_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: There are missing combinations of ids and times in `futr_df`.\nYou can run the `make_future_dataframe()` method to get the expected combinations or the `get_missing_future(futr_df)` method to get the missing combinations."
     ]
    }
   ],
   "source": [
    "forecasts = fcst.predict(futr_df=df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
